# Conversational Orchestrator Flow

## Overview
The orchestrator is the **single bot personality** that handles all conversations using an LLM-driven approach with tool calling.

---

## Main Entry Point: `handle_message()`

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User sends message via Telegram        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Extract media reference (if any)       â”‚
â”‚  Clean message text                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
         Check context
              â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
      â–¼               â–¼
 Has context?    No context
 (mid-convo)     (new request)
      â”‚               â”‚
      â”‚               â”‚
      â–¼               â–¼
_handle_answer()  _handle_new_request()
```

---

## Flow 1: New Request (`_handle_new_request()`)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Call _analyze_message()                  â”‚
â”‚     - Send message to LLM                    â”‚
â”‚     - LLM analyzes intent                    â”‚
â”‚     - LLM generates natural reply            â”‚
â”‚     - LLM optionally returns tool_call       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
       LLM returns: {
         "reply": "...",
         "tool_call": {...} or null
       }
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
        â–¼             â–¼
   Has tool_call?   No tool_call
        â”‚             â”‚
        â”‚             â”‚
        â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Execute     â”‚  â”‚ Save context:        â”‚
â”‚ tool        â”‚  â”‚ - last_message       â”‚
â”‚             â”‚  â”‚ - last_reply         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚ - waiting_for_more   â”‚
       â”‚         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚
       â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Clear       â”‚  â”‚ Return reply         â”‚
â”‚ context     â”‚  â”‚ waiting_for_input:   â”‚
â”‚             â”‚  â”‚ TRUE                 â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Return      â”‚
â”‚ reply       â”‚
â”‚ waiting:    â”‚
â”‚ FALSE       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example: Complete Task (1-turn)
```
User: "RecuÃ©rdame llamar a mi madre maÃ±ana a las 10"
  â†“
LLM analyzes â†’ Infers: TASK with all info
  â†“
LLM returns:
{
  "reply": "Perfecto! Te recordarÃ© maÃ±ana a las 10 ğŸ“",
  "tool_call": {
    "name": "create_task",
    "args": {
      "title": "llamar a mi madre",
      "due_at": "maÃ±ana 10:00"
    }
  }
}
  â†“
Orchestrator executes create_task()
  â†“
Bot: "Perfecto! Te recordarÃ© maÃ±ana a las 10 ğŸ“"
[DONE - 1 turn]
```

### Example: Incomplete Task (needs question)
```
User: "RecuÃ©rdame llamar a Juan"
  â†“
LLM analyzes â†’ Infers: TASK but missing WHEN
  â†“
LLM returns:
{
  "reply": "Claro! Â¿CuÃ¡ndo quieres que te lo recuerde?",
  "tool_call": null
}
  â†“
Orchestrator saves context:
{
  "last_message": "RecuÃ©rdame llamar a Juan",
  "last_reply": "Claro! Â¿CuÃ¡ndo quieres que te lo recuerde?",
  "waiting_for_more": true
}
  â†“
Bot: "Claro! Â¿CuÃ¡ndo quieres que te lo recuerde?"
[WAITING for user answer]
```

---

## Flow 2: Handling Answer (`_handle_answer()`)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User answers previous question              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Retrieve saved context                   â”‚
â”‚     - last_message (original request)        â”‚
â”‚     - last_reply (what we asked)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Combine context + new answer             â”‚
â”‚     "[Antes preguntÃ©: ...]                   â”‚
â”‚      Usuario responde: ..."                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Call _analyze_message() with context     â”‚
â”‚     LLM sees full conversation               â”‚
â”‚     LLM decides: more questions or execute   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
       LLM returns: {
         "reply": "...",
         "tool_call": {...} or null
       }
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
        â–¼             â–¼
   Has tool_call?   No tool_call
   (ready!)         (needs more)
        â”‚             â”‚
        â”‚             â”‚
        â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Execute     â”‚  â”‚ Update context:      â”‚
â”‚ tool        â”‚  â”‚ - last_message       â”‚
â”‚             â”‚  â”‚ - last_reply         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚
       â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Clear       â”‚  â”‚ Return reply         â”‚
â”‚ context     â”‚  â”‚ waiting_for_input:   â”‚
â”‚ DONE!       â”‚  â”‚ TRUE (continue)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Return      â”‚
â”‚ reply       â”‚
â”‚ waiting:    â”‚
â”‚ FALSE       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example: Answer Completes Task
```
[Context from before]:
{
  "last_message": "RecuÃ©rdame llamar a Juan",
  "last_reply": "Claro! Â¿CuÃ¡ndo quieres que te lo recuerde?",
  "waiting_for_more": true
}

User: "MaÃ±ana a las 10"
  â†“
Orchestrator combines:
"[Antes preguntÃ©: Claro! Â¿CuÃ¡ndo quieres que te lo recuerde?]
 Usuario responde: MaÃ±ana a las 10"
  â†“
LLM analyzes â†’ Now has all info (who: Juan, when: maÃ±ana 10:00)
  â†“
LLM returns:
{
  "reply": "Perfecto! Te recordarÃ© maÃ±ana a las 10",
  "tool_call": {
    "name": "create_task",
    "args": {
      "title": "llamar a Juan",
      "due_at": "maÃ±ana 10:00"
    }
  }
}
  â†“
Orchestrator executes create_task()
  â†“
Orchestrator clears context (conversation done)
  â†“
Bot: "Perfecto! Te recordarÃ© maÃ±ana a las 10"
[DONE - 2 turns total]
```

---

## Flow 3: Tool Execution (`_execute_tool_call()`)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM returned tool_call:                     â”‚
â”‚  {                                           â”‚
â”‚    "name": "create_task",                    â”‚
â”‚    "args": {...}                             â”‚
â”‚  }                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
       Route by tool name
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼          â–¼          â–¼          â–¼
create_task  save_note  add_to_list  search_memory
    â”‚          â”‚          â”‚          â”‚
    â–¼          â–¼          â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Call    â”‚ â”‚ Call    â”‚ â”‚ Call    â”‚ â”‚ Call    â”‚
â”‚ TaskToolâ”‚ â”‚ Memory  â”‚ â”‚ ListToolâ”‚ â”‚ Retrievalâ”‚
â”‚         â”‚ â”‚ Service â”‚ â”‚         â”‚ â”‚ Crew    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚           â”‚           â”‚           â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
         Return success/error
```

### Available Tools:

**1. `create_task`**
- Args: title, description, due_at, people, tags, media_path
- Calls: `TaskTool.create_task()`
- Returns: `{success: true, task_id: ...}`

**2. `save_note`**
- Args: content, people, tags, media_path, media_type
- Calls: `MemoryService.store_memory()`
- Returns: `{success: true}`

**3. `add_to_list`**
- Args: list_name, items
- Calls: `ListTool.add_item()`
- Returns: `{success: true, list_name: ..., items: [...]}`

**4. `search_memory`**
- Args: query
- Calls: `RetrievalCrew.search()`
- Returns: `{success: true, results: [...]}`

---

## Flow 4: LLM Analysis (`_analyze_message()`)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Construct prompt for LLM:                   â”‚
â”‚                                              â”‚
â”‚  1. User message                             â”‚
â”‚  2. Media context (if any)                   â”‚
â”‚  3. Instructions (analyze, ask, act)         â”‚
â”‚  4. Tool descriptions                        â”‚
â”‚  5. Response format (JSON)                   â”‚
â”‚  6. Examples                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Call LLM (qwen3:1.7b via Ollama)           â”‚
â”‚  - System: "Asistente conversacional..."     â”‚
â”‚  - Prompt: Full instructions + examples      â”‚
â”‚  - Format: JSON                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Decision Tree:                          â”‚
â”‚                                              â”‚
â”‚  1. ANALYZE what user wants                  â”‚
â”‚     - Task? Note? List? Search?              â”‚
â”‚                                              â”‚
â”‚  2. CHECK if info is complete                â”‚
â”‚     - Task: Has WHEN? Has WHAT?              â”‚
â”‚     - List: Has WHERE (list name)?           â”‚
â”‚     - Note: Has CONTENT?                     â”‚
â”‚                                              â”‚
â”‚  3. IF missing info â†’ ASK                    â”‚
â”‚     - "Â¿CuÃ¡ndo?" (for tasks)                 â”‚
â”‚     - "Â¿A quÃ© lista?" (for lists)            â”‚
â”‚     - "Â¿Con quiÃ©n?" (if people involved)     â”‚
â”‚     - tool_call = null                       â”‚
â”‚                                              â”‚
â”‚  4. IF complete â†’ ACT                        â”‚
â”‚     - Generate natural confirmation          â”‚
â”‚     - tool_call = {name: ..., args: {...}}   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
       Return JSON:
       {
         "reply": "Natural Spanish response",
         "tool_call": {
           "name": "create_task",
           "args": {...}
         } OR null
       }
```

### Prompt Structure:

```python
prompt = f"""Usuario: "{message}"{media_context}

Eres un asistente personal. Tu trabajo:

1. ANALIZA quÃ© quiere el usuario (tarea, nota, lista, bÃºsqueda)
2. Si falta contexto PREGUNTA naturalmente:
   - Â¿CUÃNDO? (para tareas/recordatorios)
   - Â¿CON QUIÃ‰N? (si involucra personas)
   - Â¿DÃ“NDE? (para listas: compra, trabajo, etc)
   - Nunca preguntes "Â¿quÃ© quieres hacer?" - ya lo sabes por contexto

3. DespuÃ©s de 1-2 preguntas, ACTÃšA:
   - create_task: recordatorios/tareas futuras
   - save_note: informaciÃ³n para recordar
   - add_to_list: listas (compra, trabajo, etc)
   - search_memory: buscar algo guardado

JSON: {{"reply": "...", "tool_call": {{...}} OR null}}

[Examples...]
"""

system = """Asistente conversacional en espaÃ±ol.
Haz preguntas contextuales (cuÃ¡ndo/dÃ³nde/con quiÃ©n).
DespuÃ©s de 1-2 respuestas, ejecuta la acciÃ³n.
JSON vÃ¡lido, sin markdown."""
```

### Key Principles:
- **Infer intent** - Don't ask "what do you want?"
- **Ask contextually** - When? Where? Who? (based on situation)
- **Be brief** - Max 1-2 questions before executing
- **Natural language** - Generate all text (no templates)

---

## Context Management

### Context Structure:
```python
contexts = {
  chat_id: {
    "last_message": "RecuÃ©rdame llamar a Juan",
    "last_reply": "Â¿CuÃ¡ndo quieres que te lo recuerde?",
    "waiting_for_more": True
  }
}
```

### Context Lifecycle:

```
New Request
   â†“
No context (fresh start)
   â†“
Analyze message
   â†“
IF needs more info:
  - Save context
  - waiting_for_input = True
   â†“
User answers
   â†“
Has context (retrieve)
   â†“
Analyze with context
   â†“
IF ready to execute:
  - Execute tool
  - Clear context â† IMPORTANT!
  - waiting_for_input = False
```

### Why Clear Context?
- Each conversation is independent
- No state leakage between requests
- Next message starts fresh
- Simple mental model for user

---

## Complete Example Flow

### Scenario: User wants to create a task but gives incomplete info

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Turn 1: User sends message                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
User: "RecuÃ©rdame llamar a Juan"
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Orchestrator.handle_message()                      â”‚
â”‚ - No context â†’ _handle_new_request()               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ _analyze_message()                                 â”‚
â”‚ LLM sees: "RecuÃ©rdame llamar a Juan"               â”‚
â”‚ LLM thinks:                                        â”‚
â”‚   - Intent: TASK                                   â”‚
â”‚   - What: "llamar a Juan" âœ“                        â”‚
â”‚   - When: MISSING âœ—                                â”‚
â”‚   â†’ Need to ask!                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
LLM returns:
{
  "reply": "Claro! Â¿CuÃ¡ndo quieres que te lo recuerde?",
  "tool_call": null
}
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ _handle_new_request() processes response           â”‚
â”‚ - tool_call is null â†’ needs more info              â”‚
â”‚ - Save context:                                    â”‚
â”‚   {                                                â”‚
â”‚     "last_message": "RecuÃ©rdame llamar a Juan",    â”‚
â”‚     "last_reply": "Claro! Â¿CuÃ¡ndo...",             â”‚
â”‚     "waiting_for_more": true                       â”‚
â”‚   }                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
Bot â†’ User: "Claro! Â¿CuÃ¡ndo quieres que te lo recuerde?"
             â”‚
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Turn 2: User answers                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
User: "MaÃ±ana a las 10"
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Orchestrator.handle_message()                      â”‚
â”‚ - Has context â†’ _handle_answer()                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ _handle_answer()                                   â”‚
â”‚ - Retrieve context                                 â”‚
â”‚ - Combine:                                         â”‚
â”‚   "[Antes preguntÃ©: Claro! Â¿CuÃ¡ndo...]            â”‚
â”‚    Usuario responde: MaÃ±ana a las 10"             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ _analyze_message() with combined context           â”‚
â”‚ LLM sees full conversation                         â”‚
â”‚ LLM thinks:                                        â”‚
â”‚   - Intent: TASK                                   â”‚
â”‚   - What: "llamar a Juan" âœ“                        â”‚
â”‚   - When: "maÃ±ana a las 10" âœ“                      â”‚
â”‚   â†’ All info complete, execute!                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
LLM returns:
{
  "reply": "Perfecto! Te recordarÃ© maÃ±ana a las 10",
  "tool_call": {
    "name": "create_task",
    "args": {
      "title": "llamar a Juan",
      "due_at": "maÃ±ana 10:00"
    }
  }
}
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ _handle_answer() processes response                â”‚
â”‚ - tool_call exists â†’ execute                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ _execute_tool_call()                               â”‚
â”‚ - Route to _tool_create_task()                     â”‚
â”‚ - Call TaskTool.create_task(...)                   â”‚
â”‚ - Returns: {success: true, task_id: 123}           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ _handle_answer() after execution                   â”‚
â”‚ - Clear context (conversation done)                â”‚
â”‚ - Return:                                          â”‚
â”‚   {                                                â”‚
â”‚     "message": "Perfecto! Te recordarÃ©...",        â”‚
â”‚     "waiting_for_input": False                     â”‚
â”‚   }                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
Bot â†’ User: "Perfecto! Te recordarÃ© maÃ±ana a las 10"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DONE! Task created, context cleared                â”‚
â”‚ Next message starts fresh                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Design Decisions

### 1. **Single Personality**
- Orchestrator IS the bot
- No separate intent classifier
- No separate enrichment agent
- One consistent voice

### 2. **LLM-Driven Conversation**
- LLM generates all responses
- LLM decides when to ask vs execute
- LLM formats tool calls
- No templates (except deprecated code)

### 3. **Minimal Context**
- Only last 2 turns (last_message + last_reply)
- Cleared after tool execution
- No long conversation history
- Works with small 1.7B model

### 4. **Natural Questioning**
- Ask When/Where/Who based on context
- Never ask "what do you want to do?"
- Max 1-2 questions before executing
- Infer intent from user's words

### 5. **Tool Calling Pattern**
- LLM returns: `{"reply": "...", "tool_call": {...} or null}`
- Orchestrator executes when LLM ready
- Clean separation: LLM decides, orchestrator executes
- Fallback if tool fails: show error but keep reply

---

## State Diagram

```
                    START
                      â”‚
                      â–¼
              New Message Arrives
                      â”‚
                      â–¼
              Extract Media (if any)
                      â”‚
                      â–¼
            Check for Saved Context
                      â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                â–¼
         No Context        Has Context
         (New Req)         (Answer)
              â”‚                â”‚
              â–¼                â”‚
      _handle_new_request()    â”‚
              â”‚                â”‚
              â–¼                â”‚
      _analyze_message()       â”‚
              â”‚                â”‚
              â–¼                â”‚
      LLM Decision             â”‚
              â”‚                â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
      â–¼                â–¼       â”‚
  tool_call?      No tool      â”‚
      â”‚                â”‚       â”‚
      â–¼                â–¼       â”‚
   Execute         Save        â”‚
   Tool            Context â”€â”€â”€â”€â”˜
      â”‚                â”‚
      â–¼                â–¼
  Clear          Return Reply
  Context        (waiting=true)
      â”‚
      â–¼
  Return Reply
  (waiting=false)
      â”‚
      â–¼
    DONE

[Next message starts fresh if context was cleared]
[Next message continues conversation if context saved]
```

---

## Error Handling

### JSON Parsing Errors
```python
try:
    result = self.llm.generate_json(prompt, system_prompt)
    if "reply" not in result:
        result["reply"] = "Lo siento, no entendÃ­ bien."
    if "tool_call" not in result:
        result["tool_call"] = None
    return result
except Exception as e:
    return {
        "reply": "PerdÃ³n, tuve un problema. Â¿Puedes repetir?",
        "tool_call": None
    }
```

### Tool Execution Errors
```python
try:
    result = await self._execute_tool_call(tool_call, media_ref, user_id)
    return {"message": reply, "waiting_for_input": False}
except Exception as e:
    return {
        "message": f"{reply}\n\n(Error: {str(e)})",
        "waiting_for_input": False
    }
```

### Graceful Degradation
- If LLM fails â†’ Ask user to repeat
- If tool fails â†’ Show error but keep LLM's message
- If JSON invalid â†’ Use defaults (reply + no tool_call)
- Never crash, always respond

---

## Performance Considerations

### For 1.7B Model (qwen3:1.7b):
- âœ… Lean prompts (~200 tokens)
- âœ… Minimal context (2 turns max)
- âœ… Clear examples in prompt
- âœ… Simple JSON format
- âš ï¸ May struggle with complex tool calls
- âš ï¸ May need prompt refinement

### Latency:
- 1 LLM call per turn (new request)
- 1 LLM call per turn (answer)
- Tool execution ~50-200ms
- Total: ~1-3 seconds per interaction

### Fallback Strategy:
If qwen3:1.7b struggles with tool calling:
- **Option B**: LLM generates text only, orchestrator handles logic
- Keep natural conversation
- Simpler for small model
- Still feels natural to user
